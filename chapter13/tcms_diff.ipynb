{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pid</th>\n",
       "      <th>contxt</th>\n",
       "      <th>diag_code</th>\n",
       "      <th>tcms_code</th>\n",
       "      <th>tan</th>\n",
       "      <th>feng</th>\n",
       "      <th>ren</th>\n",
       "      <th>yinxu</th>\n",
       "      <th>fei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1803613</td>\n",
       "      <td>右肺癌术后三月余。 患者面色憔悴；形体消瘦，无咳喘，无喉中水鸡声；言语清晰、流畅；气息平和；...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1802607</td>\n",
       "      <td>右肺癌术后两月余。 患者面色憔悴；形体消瘦，无咳喘，无喉中水鸡声；言语清晰、流畅；气息平和；...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1809724</td>\n",
       "      <td>右肺癌术后8年余，咳嗽气喘加重1周。 患者气喘貌，无喉中水鸡声；言语清晰、流畅；气息尚平和；...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1710003</td>\n",
       "      <td>右肺癌术后8年余，反复咳嗽气喘半年余。 患者气喘貌，无喉中水鸡声；言语清晰、流畅；气息尚平和...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1613461</td>\n",
       "      <td>右肺癌术后7年余，咳嗽气喘20小时。 患者气喘貌，无喉中水鸡声；言语清晰、流畅；气息尚平和；...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      pid                                             contxt  diag_code  \\\n",
       "0   1  1803613  右肺癌术后三月余。 患者面色憔悴；形体消瘦，无咳喘，无喉中水鸡声；言语清晰、流畅；气息平和；...          0   \n",
       "1   2  1802607  右肺癌术后两月余。 患者面色憔悴；形体消瘦，无咳喘，无喉中水鸡声；言语清晰、流畅；气息平和；...          0   \n",
       "2   3  1809724  右肺癌术后8年余，咳嗽气喘加重1周。 患者气喘貌，无喉中水鸡声；言语清晰、流畅；气息尚平和；...          0   \n",
       "3   4  1710003  右肺癌术后8年余，反复咳嗽气喘半年余。 患者气喘貌，无喉中水鸡声；言语清晰、流畅；气息尚平和...          0   \n",
       "4   5  1613461  右肺癌术后7年余，咳嗽气喘20小时。 患者气喘貌，无喉中水鸡声；言语清晰、流畅；气息尚平和；...          0   \n",
       "\n",
       "   tcms_code  tan  feng  ren  yinxu  fei  \n",
       "0          2    0     0    0      1    1  \n",
       "1          2    0     0    0      1    1  \n",
       "2          2    0     0    0      1    1  \n",
       "3          2    0     0    0      1    1  \n",
       "4          2    0     0    0      1    1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(\"./data/data_demo.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.tcms_code\n",
    "tcme=data.iloc[:,5:]\n",
    "context=data.contxt\n",
    "diag=data.diag_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400,) (1400, 5) (1400,) (1400,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape,tcme.shape,context.shape,diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictfile=\"./data/tcm_all_dict_2.txt\"\n",
    "stopwords=\"./data/stopwords.txt\"\n",
    "jieba.load_userdict(dictfile)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2doc1(infile,dictfile):    \n",
    "    #jieba.load_userdict(dictfile)                     \n",
    "    doc = [w for x in codecs.open(file_name, 'r', 'utf-8').readlines() for w in jieba.cut(x.strip())]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopword(filename):  \n",
    "    stopwords = [line.strip() for line in open(filename, 'r', encoding='utf-8').readlines()]  \n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_alnum(astr):\n",
    "    drop_str=\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    str1=astr\n",
    "    for ch in str1:\n",
    "        if ch in drop_str:\n",
    "            str1=str1.replace(ch,\"\")\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_neg_txt1(contxt):\n",
    "    txt=contxt\n",
    "    endtxt=\"\"\n",
    "    txttmp=\"\"\n",
    "    item0=\"无\"   \n",
    "    item1=[\"；\",\"，\",\"舌\"] \n",
    "    #item1=[\"；\",\"，\"]\n",
    "\n",
    "    for i in range(len(contxt)):\n",
    "        if txt.find(item0)>0:\n",
    "            start=txt.find(item0)\n",
    "            subtxt1=txt[:start]\n",
    "            txttmp+=subtxt1\n",
    "            #print(txttmp+\"\\n\")\n",
    "            subtxt=txt[start:]\n",
    "            #print(subtxt+\"\\n\")\n",
    "    \n",
    "            for sign in item1:        \n",
    "                if subtxt.find(sign)>0:        \n",
    "                    end=subtxt.find(sign)        \n",
    "                    break \n",
    "            txt=subtxt[end:]\n",
    "            #print(txt+\"\\n\")\n",
    "        endtxt=txt\n",
    "        \n",
    "    txttmp+=endtxt\n",
    "    #print(txttmp+\"\\n\")\n",
    "    return txttmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_neg_txt2(contxt):\n",
    "    txt=contxt\n",
    "    endtxt=\"\"\n",
    "    txttmp=\"\"\n",
    "    item0=\"未\"\n",
    "    item1=[\"；\",\"，\",\"有\"] \n",
    "    #item1=[\"；\",\"，\"]\n",
    "\n",
    "    for i in range(len(contxt)):\n",
    "        if txt.find(item0)>0:\n",
    "            start=txt.find(item0)\n",
    "            subtxt1=txt[:start]\n",
    "            txttmp+=subtxt1\n",
    "            #print(txttmp+\"\\n\")\n",
    "            subtxt=txt[start:]\n",
    "            #print(subtxt+\"\\n\")\n",
    "    \n",
    "            for sign in item1:        \n",
    "                if subtxt.find(sign)>0:        \n",
    "                    end=subtxt.find(sign)        \n",
    "                    break \n",
    "            txt=subtxt[end:]\n",
    "            #print(txt+\"\\n\")\n",
    "        endtxt=txt\n",
    "        \n",
    "    txttmp+=endtxt\n",
    "    #print(txttmp+\"\\n\")\n",
    "    return txttmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_neg(context):\n",
    "    corpus=[]    \n",
    "    \n",
    "    for sent in context:\n",
    "        sent=sent+\"；\"\n",
    "        sent=del_neg_txt1(sent) #drop negative words  \n",
    "        sent=del_neg_txt2(sent)\n",
    "        sent.strip(\"；\")        \n",
    "        corpus.append(sent)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_ng = get_text_neg(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_pd=pd.DataFrame(txt_ng)\n",
    "txt_pd.to_excel(\"txt_pos.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(context):\n",
    "    corpus=[]    \n",
    "    \n",
    "    for sent in context:\n",
    "        sent=sent+\"；\"\n",
    "        sent=del_neg_txt1(sent) #drop negative words  \n",
    "        sent=del_neg_txt2(sent)\n",
    "        sent.strip(\"；\")\n",
    "        strlist=list(jieba.cut(sent))\n",
    "        strlist=sorted(set(strlist),key=strlist.index)\n",
    "        corpus.append(strlist)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus1(doc,stopwords):    \n",
    "    stopword_list=load_stopword(stopwords)   \n",
    "    #r1 = u'[a-zA-Z0-9’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~]+'   #drop letters, numbers and sepcial chars\n",
    "    out=[]\n",
    "    \n",
    "    for sent in doc:        \n",
    "        doc_stopword=[y for y in sent if y not in stopword_list] #drop stopword\n",
    "        res=[]\n",
    "        for y in doc_stopword:\n",
    "            #res.append(re.sub(r1,\"\",y))   #drop letters, numbers and sepcial chars\n",
    "            y=drop_alnum(y)\n",
    "            res.append(y)  #drop letters, numbers and sepcial chars\n",
    "        out.append(res)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "atxt=get_corpus(context)\n",
    "cps=get_corpus1(atxt, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextCNN - TCM syndrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH =64\n",
    "EMBEDDING_DIM = 256\n",
    "VALIDATION_SPLIT = 0.16 \n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1008 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "y=data.tcms_code\n",
    "all_texts=cps\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_texts)\n",
    "sequences = tokenizer.texts_to_sequences(all_texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "datatxt = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = to_categorical(np.asarray(y),num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=datatxt\n",
    "y1=labels\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y1,test_size=0.2,random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Sequential\n",
    "#EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 64, 256)           258304    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 64, 512)           393728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 32, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,849,162\n",
      "Trainable params: 4,849,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(512, 3, padding='same', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(EMBEDDING_DIM, activation='relu'))\n",
    "model.add(Dense(labels.shape[1], activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 224 samples\n",
      "Epoch 1/8\n",
      "896/896 [==============================] - 4s 4ms/step - loss: 1.0582 - acc: 0.5379 - val_loss: 0.6862 - val_acc: 0.7500\n",
      "Epoch 2/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.3965 - acc: 0.8549 - val_loss: 0.2549 - val_acc: 0.8973\n",
      "Epoch 3/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.1444 - acc: 0.9531 - val_loss: 0.1668 - val_acc: 0.9286\n",
      "Epoch 4/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0782 - acc: 0.9766 - val_loss: 0.1711 - val_acc: 0.9196\n",
      "Epoch 5/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0476 - acc: 0.9855 - val_loss: 0.1677 - val_acc: 0.9241\n",
      "Epoch 6/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0300 - acc: 0.9911 - val_loss: 0.2356 - val_acc: 0.9196\n",
      "Epoch 7/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0332 - acc: 0.9900 - val_loss: 0.2148 - val_acc: 0.9286\n",
      "Epoch 8/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0179 - acc: 0.9955 - val_loss: 0.2144 - val_acc: 0.9241\n",
      "accuracy: 0.8714285731315613\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.fit(x_train, y_train, batch_size=64, epochs=4, verbose=1, validation_data=(x_test, y_test)) \n",
    "model.fit(x_train, y_train, batch_size=32, epochs=8, verbose=1, validation_split=0.2, shuffle=True) \n",
    "#score1 = model.evaluate(x_train,y_train, verbose=0)\n",
    "score2 = model.evaluate(x_test,y_test, verbose=0)\n",
    "print(\"accuracy:\",score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TextCNN - TCM element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH =64\n",
    "EMBEDDING_DIM = 256\n",
    "VALIDATION_SPLIT = 0.16 \n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb=MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1008 unique tokens.\n",
      "Shape of data tensor: (1400, 64)\n",
      "Shape of label tensor: (1400, 5)\n",
      "{' ': 1, '咳嗽': 2, '咳痰': 3, '患者': 4, '为主': 5, '舌质': 6, '精神': 7, '面色': 8, '诉': 9, '结合': 10, '红': 11, '苔': 12, '舌脉': 13, '痰': 14, '清晰': 15, '阵发性': 16, '天': 17, '发热': 18, '二便': 19, '言语': 20, '伴': 21, '脉滑': 22, '胸闷': 23, '稍': 24, '气喘': 25, '正常': 26, '神清': 27, '咯痰': 28, '形体': 29, '双目': 30, '呼吸': 31, '发育': 32, '营养': 33, '应答': 34, '自如': 35, '语声': 36, '调': 37, '少神': 38, '有神': 39, '清': 40, '黄腻': 41, '食纳': 42, '少华': 43, '舌红': 44, '平稳': 45, '适中': 46, '行动自如': 47, '淡红': 48, '白腻': 49, '加重': 50, '后': 51, '表情': 52, '声音洪亮': 53, '脉浮': 54, '月余': 55, '尚可': 56, '神志': 57, '不易': 58, '活动': 59, '苔薄': 60, '咯出': 61, '气促': 62, '一周': 63, '': 64, '精神不振': 65, '数': 66, '黄': 67, '脉滑数': 68, '中等': 69, '脉细': 70, '症': 71, '脉细数': 72, '响亮': 73, '苔少': 74, '肺癌': 75, '乏力': 76, '患儿': 77, '良好': 78, '余': 79, '咯': 80, '粘': 81, '欠佳': 82, '自然': 83, '三天': 84, '咯吐': 85, '粘痰': 86, '十余天': 87, '时有': 88, '伴有': 89, '月': 90, '痛苦': 91, '咳声': 92, '纳差': 93, '气息': 94, '平和': 95, '流畅': 96, '少苔': 97, '少量': 98, '轻微': 99, '睡眠': 100, '白色': 101, '胸痛': 102, '反复': 103, '明显': 104, '咳出': 105, '薄': 106, '红润': 107, '神识': 108, '憔悴': 109, '不': 110, '舌': 111, '不适': 112, '一天': 113, '入院': 114, '白痰': 115, '四天': 116, '白': 117, '畏寒': 118, '呈': 119, '痰中带血': 120, '语声低微': 121, '面容': 122, '微黄': 123, '腻': 124, '发现': 125, '确诊': 126, '右': 127, '量': 128, '年': 129, '术后': 130, '周': 131, '五天': 132, '消瘦': 133, '偶有': 134, '不佳': 135, '咯血': 136, '余天': 137, '间断': 138, '干咳': 139, '疼痛': 140, '两天': 141, '差': 142, '黄白': 143, '收住': 144, '黄痰': 145, '粘色': 146, '岁': 147, '一月': 148, '白量': 149, '占位': 150, '少': 151, '小时': 152, '半月': 153, '间': 154, '舌淡': 155, '荣润': 156, '色': 157, '少许': 158, '质': 159, '全身': 160, '年余': 161, '化疗': 162, '左侧': 163, '欠振': 164, '稍腻': 165, '苔薄白': 166, '扁桃体': 167, '门诊': 168, '右侧': 169, '证': 170, '脉象': 171, '偏淡': 172, '男': 173, '尚调': 174, '阵发': 175, '舌苔': 176, '尚': 177, '量少': 178, '萎': 179, '苔腻': 180, '咳白': 181, '喉间': 182, '咽红': 183, '畅': 184, '咯吐白': 185, '自觉': 186, '双侧': 187, '潮红': 188, '饮食': 189, '时': 190, '感': 191, '再发': 192, '右肺': 193, '淡': 194, '不能': 195, '色白': 196, '程后': 197, '大便': 198, '少痰': 199, '黄色': 200, '两': 201, '动则': 202, '半天': 203, '纳食': 204, '难以': 205, '苔薄少': 206, '二十余天': 207, '纳眠': 208, '一年': 209, '尤甚': 210, '余年': 211, '尚有': 212, '神': 213, '脉细弱': 214, '吐': 215, '天伴': 216, '左肺': 217, '胀痛': 218, '稍红': 219, '尚畅': 220, '剧烈': 221, '出': 222, '咽': 223, '皮疹': 224, '干': 225, '瘦': 226, '小便': 227, '连咳': 228, '约': 229, '肿大': 230, '稍促': 231, '欠安': 232, '苔脉': 233, '咳嗽气喘': 234, '黑': 235, '气急': 236, '散': 237, '语': 238, '恶心': 239, '夜寐': 240, '头痛': 241, '°': 242, '热性': 243, '胸廓': 244, '桶装': 245, '转移': 246, '双下肢': 247, '头晕': 248, '鲜红': 249, '休息': 250, '稠痰': 251, '苔白': 252, '咳吐白': 253, '脉弦': 254, '咽痒': 255, '鸣': 256, '十天': 257, '易咯': 258, '放化疗': 259, '背部': 260, '夜间': 261, '咳血': 262, '喉中': 263, '胸部': 264, '口': 265, '稍感': 266, '萎靡': 267, '脉数': 268, '白质': 269, '貌': 270, '半年': 271, '肺部': 272, '不安': 273, '连声': 274, '尚易': 275, '气管': 276, '切开': 277, '腹胀': 278, '浮肿': 279, '咽痛': 280, '恶寒发热': 281, '咳吐': 282, '稍萎': 283, '嗜睡': 284, '四月': 285, '下肢': 286, '气短': 287, '时感': 288, '血丝': 289, '黄白色': 290, '乏神': 291, '神志不清': 292, '放疗': 293, '左': 294, '细胞': 295, '通畅': 296, '肋部': 297, '后感': 298, '舌质暗红': 299, '仍': 300, '欲': 301, '晄': 302, '多色': 303, '三月': 304, '脉': 305, '骨转移': 306, '进食': 307, '小': 308, '血色': 309, '相间': 310, '暂': 311, '痰量': 312, '咯白': 313, '泡沫': 314, '夜寐尚安': 315, '黄量': 316, '面色萎白': 317, 'ⅱ': 318, 'ⅰ': 319, '肝': 320, '女': 321, '呕吐': 322, '背痛': 323, '左下': 324, '肺非': 325, '伴肝': 326, '细': 327, '胁': 328, '部': 329, '暗红': 330, '减轻': 331, '干咳少痰': 332, '近': 333, '样痰': 334, '急促': 335, '脑外伤': 336, '粘量': 337, '易于': 338, '进行性': 339, '肺': 340, '偏红': 341, '水肿': 342, '缓解': 343, '夜寐安': 344, '胸': 345, '恶心呕吐': 346, '晨起': 347, '反酸': 348, '上': 349, '腹部': 350, '阵作': 351, '黄质': 352, '六天': 353, '两周': 354, '厚腻': 355, '尚平': 356, '声嘶': 357, '腹泻': 358, '痛': 359, '两月': 360, '鲜红色': 361, '中': 362, '平卧': 363, '声音': 364, '较响': 365, '晦暗': 366, '黄粘痰': 367, '黏': 368, '丝': 369, '体温': 370, '易': 371, '深吸气': 372, '寒战': 373, '呼吸困难': 374, '夹': 375, '脑出血': 376, '七年': 377, '质稠': 378, '痰质': 379, '粘稠': 380, '二十天': 381, '充血': 382, '肢体': 383, '神疲乏力': 384, '腺癌': 385, '脑': 386, '伴咽': 387, '脉弦滑': 388, '隐痛': 389, '性': 390, '模糊': 391, '咳时': 392, '再': 393, '发伴': 394, '结代': 395, '咳黄': 396, '嘶哑': 397, '心慌': 398, '偶咳': 399, '最高': 400, '.': 401, '食纳夜': 402, '寐': 403, '食': 404, '食纳及': 405, '粘难': 406, '七天': 407, '辨病': 408, '哭声': 409, '半余': 410, '五月': 411, '苔薄腻': 412, '咯较': 413, '本案': 414, '夜寐差': 415, '苦': 416, '久立': 417, '鼻塞': 418, '间发': 419, '面': 420, '不清': 421, '见': 422, '泡沫痰': 423, '舌红少苔': 424, '骨折': 425, '昏迷': 426, '十余年': 427, '浅黄色': 428, '酸痛': 429, '声咳': 430, '间歇性': 431, '治疗': 432, '咳喘': 433, '两年': 434, '腰痛': 435, '半': 436, '皮肤': 437, '平': 438, '意识': 439, '四年': 440, '痰色': 441, '病变': 442, '肿块': 443, '结': 444, '刺激性': 445, '胃脘': 446, '颈部': 447, '暂时': 448, '困难': 449, '虚火': 450, '灼络': 451, '肺络': 452, '损伤': 453, '咽干': 454, '中带': 455, '甚': 456, '盗汗': 457, '鳞癌': 458, '摄氏度': 459, '腹痛': 460, '外伤': 461, '颈椎': 462, '脓痰': 463, '一次': 464, '保留': 465, '导尿': 466, '多质': 467, '大量': 468, '交流': 469, '六月': 470, '四肢': 471, '淡紫': 472, '清楚': 473, '规则': 474, '次': 475, '复发': 476, '伽马刀': 477, '障碍': 478, '后近': 479, '朱秋生': 480, '增高': 481, '斑疹': 482, '相': 483, '周余': 484, '轻度': 485, '九月': 486, '三年': 487, '骨痛': 488, '脸颊': 489, '凹陷': 490, '纳可': 491, '主诉': 492, '夜寐可': 493, '日': 494, '胸胁': 495, '痒': 496, '斤': 497, '症状': 498, '暗红色': 499, '深呼吸': 500, '影响': 501, '流清涕': 502, '恶心欲呕': 503, '鼻饲': 504, '口干口': 505, '局部': 506, '皮温': 507, '不高': 508, '慢性': 509, '十余': 510, '反应': 511, '黄微腻': 512, '恶寒': 513, '持续性': 514, '脉弦数': 515, '口中': 516, '面色萎黄': 517, '尚安': 518, '尚清': 519, '难咯': 520, '低热': 521, '黄易': 522, '少质': 523, '人': 524, '少色': 525, '尚能': 526, '夹有': 527, '抽搐': 528, '流涕': 529, '天余': 530, '指纹': 531, '隐于': 532, '风关': 533, '端坐': 534, '难解': 535, '鲜血': 536, '站立': 537, '细涩': 538, '三周': 539, '淋巴结': 540, '体检': 541, '体态': 542, '脉略细': 543, '手足心热': 544, '烦躁': 545, '肿胀': 546, '诊断': 547, '十一月': 548, '腰背痛': 549, '主要症状': 550, '左手': 551, '重度': 552, '多易': 553, '腹肌': 554, '内容': 555, '右手': 556, '较差': 557, '及右': 558, '现': 559, '服用': 560, '盐酸': 561, '吗啡': 562, '缓释片': 563, '止痛': 564, '效果': 565, '好转': 566, '肩痛': 567, '胸前': 568, '粉红色': 569, '近期': 570, '体重': 571, '下降': 572, '紧': 573, '改变': 574, '近两年来': 575, '少难': 576, '大小便': 577, '低微': 578, '血量': 579, '样': 580, '头部': 581, '饮': 582, '次数': 583, '心悸': 584, '不成形': 585, '咽部': 586, '异物感': 587, '倦怠': 588, '窦': 589, '道': 590, '脓液': 591, '流出': 592, '频繁': 593, '反应迟钝': 594, '稍显': 595, '迟钝': 596, '轻': 597, '重': 598, '高热': 599, '气粗': 600, '仍感': 601, '身痛': 602, '二月': 603, '食管癌': 604, '不详': 605, '欠清': 606, '失禁': 607, '面色苍白': 608, '咽痛伴': 609, '仍诉': 610, '三': 611, '口唇': 612, '肌肉': 613, '汗出': 614, '排痰': 615, '流质': 616, '呃逆': 617, '十五天': 618, '稍白': 619, '五年': 620, '数日': 621, '苔浊': 622, '稍事': 623, '突发': 624, '十月': 625, '八月': 626, '自主': 627, '稀': 628, '痴呆': 629, '状': 630, '发作': 631, '二天': 632, '双手': 633, '半卧位': 634, '更': 635, '偶作': 636, '喉': 637, '口腔': 638, '间歇': 639, '下眼睑': 640, '前': 641, '质红': 642, '濡': 643, '滑': 644, '颜面': 645, '皆': 646, '热内': 647, '盛之证': 648, '长期': 649, '剑': 650, '突下': 651, '多难': 652, '右中': 653, '肺叶切除术': 654, '解': 655, '粘液性': 656, '血便': 657, '跌倒': 658, '二': 659, '腰背': 660, '唐有': 661, '德': 662, '纵膈': 663, '臧根生': 664, '肋间': 665, '一程': 666, '瘤': 667, '介入': 668, '末次': 669, '弦': 670, '蔡秀娣': 671, '胸膜': 672, '舌淡苔薄白': 673, '次后': 674, '三程': 675, '两程': 676, '左乳': 677, '多发性': 678, '多发': 679, '时时': 680, '胸腔积液': 681, '右下': 682, '行走': 683, '背': 684, '红肿': 685, '贫血': 686, '右胁': 687, '右上': 688, '娥': 689, '耳边': 690, '哎调': 691, '结节': 692, '上半身': 693, '出汗': 694, '间感': 695, '较前': 696, '邱': 697, '脐下': 698, '视物': 699, '肺大泡': 700, '乳腺癌': 701, '肋': 702, '便秘': 703, '区': 704, '泛酸': 705, '劳累': 706, '血小板减少': 707, '综合': 708, '半个': 709, '带血': 710, '体征': 711, '病史': 712, '中医': 713, '性质': 714, '块': 715, '踝关节': 716, '血液': 717, '上肢': 718, '瘫痪': 719, '双': 720, '头颈部': 721, '吞咽': 722, '闷胀': 723, '食入': 724, '红少苔': 725, '水样': 726, '稀便': 727, '饱胀': 728, '自愈': 729, '持续': 730, '多食': 731, '多尿': 732, '黄脉': 733, '体位': 734, '伴间': 735, '发': 736, '胃': 737, '物': 738, '说胡话': 739, '胸骨': 740, '前区': 741, '日间': 742, '失控': 743, '区及': 744, '咳嗽声': 745, '嘶': 746, '结节病': 747, '变': 748, '手术': 749, '之少神': 750, '不欲': 751, '入睡': 752, '肩部': 753, '血': 754, '少苔脉': 755, '左胁': 756, '苔红': 757, '舌舌质': 758, '十一': 759, '杨雪军': 760, '男性': 761, '待查': 762, '急诊': 763, '身': 764, '困乏': 765, '力': 766, '伴身': 767, '枕叶': 768, '弥漫': 769, '大': 770, '淋巴瘤': 771, '胁痛': 772, '协痛': 773, '股骨': 774, '转子': 775, '受限': 776, '基底节': 777, '血肿': 778, '穿刺': 779, '引流术': 780, '四': 781, '血糖': 782, '数十口': 783, '术': 784, '七月': 785, '腰大池': 786, '腹腔分流术': 787, '二周': 788, '呼之能': 789, '睁眼': 790, '执行': 791, '简单': 792, '指令': 793, '近身': 794, '闻及': 795, '异常': 796, '气味': 797, '以纳少': 798, '口干': 799, '尿': 800, '喘伴': 801, '程度': 802, '仅': 803, '咳嗽痰多': 804, '曾': 805, '加剧': 806, '黄脓质': 807, '粘尚能': 808, '偏暗': 809, '致': 810, '紫绀': 811, '排尿': 812, '色黄': 813, '苍白': 814, '季肋区': 815, '唤之能': 816, '醒': 817, '准确': 818, '回答': 819, '问题': 820, '样粘痰': 821, '稍差': 822, '十二天': 823, '十多天': 824, '可咯': 825, '体型': 826, '自行': 827, '三十余': 828, '周身': 829, '夜': 830, '尿频': 831, '日一解': 832, '并感': 833, '两侧': 834, '质稠尚': 835, '极度': 836, '钝痛': 837, '黄难': 838, '耐力': 839, '减低': 840, '一解': 841, '针刺': 842, '伴食': 843, '萎稍': 844, '恶心感': 845, '喘': 846, '六小时': 847, '淡漠': 848, '鼻唇沟': 849, '不浅': 850, '口角': 851, '暗': 852, '平时': 853, '增多': 854, '鸣音': 855, '辨证': 856, '依据': 857, '少数': 858, '中等量': 859, '偏干': 860, '疑难': 861, '危重': 862, '病例': 863, '讨论': 864, '记录': 865, '地点': 866, '八': 867, '病区': 868, '医生': 869, '办公室': 870, '参加': 871, '人员': 872, '朱正辉科': 873, '主任医师': 874, '王雪梅': 875, '主治': 876, '中医师': 877, '束燕铭': 878, '谭寅巍': 879, '住院医师': 880, '周一': 881, '民': 882, '王玉瑾': 883, '住院': 884, '有力': 885, '大便干结': 886, '胀满': 887, '后咽': 888, '呛咳': 889, '十小时': 890, '白尚易': 891, '时伴': 892, '下腹': 893, '不利': 894, '暂缺': 895, '色白易咯': 896, '伴月': 897, '欠畅': 898, '调畅': 899, '嗳气': 900, '颤动': 901, '偏少': 902, '排出': 903, '较易': 904, '具体': 905, '手麻': 906, '失眠': 907, '外感': 908, '风热': 909, '风热犯': 910, '肺失': 911, '宣降': 912, '犯表': 913, '卫表': 914, '热邪': 915, '蒸津': 916, '见口': 917, '薄黄': 918, '黄脉滑': 919, '单选': 920, '软瘫': 921, '昏睡': 922, '颈项': 923, '头闷': 924, '手足': 925, '吐泻': 926, '表面': 927, '脓性': 928, '分泌物': 929, '疲乏': 930, '内': 931, '周伴': 932, '流黄': 933, '浓涕': 934, '偶阵': 935, '双眼': 936, '球': 937, '结膜': 938, '天余伴': 939, '声': 940, '拇指': 941, '第一': 942, '指关节': 943, '肿痛': 944, '呕血': 945, '八小时': 946, '四十天': 947, '安': 948, '麻木': 949, '汗': 950, '刻': 951, '少易': 952, '不祥': 953, '酸胀': 954, '间质性': 955, '肺病': 956, '吴锁根': 957, '现在': 958, '雷诺': 959, '现象': 960, '僵硬': 961, '多处': 962, '破溃': 963, '低弱': 964, '脉虚细': 965, '食欲': 966, '咯吐黄': 967, '偶': 968, '促': 969, '头昏': 970, '偶感': 971, '行动迟缓': 972, '白糖': 973, '头胀': 974, '痛痛': 975, '前额': 976, '饮水': 977, '大声': 978, '说话': 979, '及胁': 980, '伴胸': 981, '天大': 982, '便': 983, '带有': 984, '三次': 985, '咯痰不爽': 986, '起初': 987, '总量': 988, '两口': 989, '病程': 990, '黄干': 991, '液': 992, '口干咽': 993, '再次': 994, '现转': 995, '排尿困难': 996, '腰骶部': 997, '劳力': 998, '青': 999, '半身不遂': 1000, '少气': 1001, '懒言': 1002, '少白': 1003, '中喘鸣': 1004, '沉细': 1005, '时量': 1006, '烧心': 1007, '粘易': 1008}\n"
     ]
    }
   ],
   "source": [
    "ym=pd.DataFrame(tcme)\n",
    "\n",
    "all_texts=cps\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_texts)\n",
    "sequences = tokenizer.texts_to_sequences(all_texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "datatxt = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "#labels = to_categorical(np.asarray(y),num_classes=None)\n",
    "print('Shape of data tensor:', datatxt.shape)\n",
    "print('Shape of label tensor:', ym.shape)\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=datatxt\n",
    "#ym=pd.DataFrame(outm)\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,ym,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tan</th>\n",
       "      <th>feng</th>\n",
       "      <th>ren</th>\n",
       "      <th>yinxu</th>\n",
       "      <th>fei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tan  feng  ren  yinxu  fei\n",
       "1110    0     1    1      0    1\n",
       "310     1     0    1      0    1\n",
       "776     1     0    0      0    1\n",
       "491     1     0    1      0    1\n",
       "1063    0     1    1      0    1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Sequential\n",
    "#EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\code\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From d:\\code\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 64, 256)           258304    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 64, 512)           393728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 32, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 4,847,877\n",
      "Trainable params: 4,847,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(512, 3, padding='same', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(EMBEDDING_DIM, activation='relu'))\n",
    "#model.add(Dense(ym.shape[1], activation='softmax')) #multiclass\n",
    "model.add(Dense(ym.shape[1], activation='sigmoid')) #multilabel\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\code\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 896 samples, validate on 224 samples\n",
      "Epoch 1/8\n",
      "896/896 [==============================] - 4s 4ms/step - loss: 0.3457 - acc: 0.8429 - val_loss: 0.2034 - val_acc: 0.9268\n",
      "Epoch 2/8\n",
      "896/896 [==============================] - 3s 3ms/step - loss: 0.1059 - acc: 0.9629 - val_loss: 0.1247 - val_acc: 0.9562\n",
      "Epoch 3/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0480 - acc: 0.9801 - val_loss: 0.1193 - val_acc: 0.9625\n",
      "Epoch 4/8\n",
      "896/896 [==============================] - 4s 4ms/step - loss: 0.0248 - acc: 0.9911 - val_loss: 0.1196 - val_acc: 0.9634\n",
      "Epoch 5/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0130 - acc: 0.9953 - val_loss: 0.1285 - val_acc: 0.9598\n",
      "Epoch 6/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0088 - acc: 0.9964 - val_loss: 0.1320 - val_acc: 0.9625\n",
      "Epoch 7/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0064 - acc: 0.9975 - val_loss: 0.1408 - val_acc: 0.9652\n",
      "Epoch 8/8\n",
      "896/896 [==============================] - 3s 4ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.1516 - val_acc: 0.9625\n",
      "0.9750000068119594\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"acc\"]) \n",
    "#model.fit(x_train, y_train, batch_size=64, epochs=4, verbose=1, validation_data=(x_test, y_test)) \n",
    "model.fit(x_train, y_train, batch_size=32, epochs=8, verbose=1, validation_split=0.2, shuffle=True)\n",
    "score = model.evaluate(x_test,y_test, verbose=0)\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
